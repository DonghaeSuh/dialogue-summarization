{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output 문장 구조 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a json file and return a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): Path to the json file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame of the json file.\n",
    "    \"\"\"\n",
    "    # Read the json file\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    # columns = ['id', 'conversation', 'subject_keyword', 'output']\n",
    "    df = pd.DataFrame(data)\n",
    "    df['conversation'] = df['input'].apply(lambda x: x['conversation'])\n",
    "    df['subject_keyword'] = df['input'].apply(lambda x: x['subject_keyword'])\n",
    "\n",
    "    # Drop the 'input' column\n",
    "    df.drop('input', axis=1, inplace=True)\n",
    "\n",
    "    # Speakers in the conversation\n",
    "    df['speakers'] = df['conversation'].apply(lambda turns: list(set(turn['speaker'] for turn in turns)))\n",
    "\n",
    "    # Reorder the columns\n",
    "    df = df[['id', 'conversation', 'subject_keyword', 'speakers', 'output']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_dataframe('../resource/data/일상대화요약_train.json')\n",
    "dev_df = make_dataframe('../resource/data/일상대화요약_dev.json')\n",
    "test_df = make_dataframe('../resource/data/일상대화요약_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output의 구문 구조의 정성적 평가 결과에 따른 정량적 평가\n",
    "\n",
    "\n",
    "### 정성적 평가 결과output은 총 3가지 구조로 이루어져 있음\n",
    "\n",
    "- 맨 처음에 **전반적인 요약** 이 나오고\n",
    "- 두 번째로 **speaker 1**이 한 말에 대한 요약이 나오고\n",
    "- 세 번째로 **speaker 2**가 한 말에 대한 요약으로 마무리된다\n",
    "\n",
    "<br/>\n",
    "\n",
    "- 실제로 모든 데이터가 위와 같은 구조로 이루어져 있는지를 통계로 확인\n",
    "\n",
    "\n",
    "    - **문장 안에 speaker1과 speaker2가 모두 존재하는지 확인**\n",
    "\n",
    "        - 모두 존재함!\n",
    "\n",
    "    <br/>\n",
    "\n",
    "    - **그 순서가 speaker1, speaker2 순서로 이루어져 있는지 확인**\n",
    "\n",
    "        - 모두 그렇지는 않음! \n",
    "        - train dataset의 경우 506개 중에 328개\n",
    "            \n",
    "    <br/>\n",
    "            \n",
    "    - **그렇다면, conversation의 시작하는 speaker가 맨 앞에 오고, 그 다음 speaker가 뒤에 오는 순서인가?**\n",
    "\n",
    "        - 위의 sample과 이어지는 다음 sample인 경우 speaker2가 먼저 conversation을 시작하기도 함\n",
    "        - train dataset의 경우 492 / 506, dev dataset의 경우 100 / 102\n",
    "            \n",
    "\n",
    "### 결론\n",
    "- 일단 conversation을 시작하는 speaker가 첫번째로 요약되고, 그 이후 그 다음 speaker가 요약되는 경우가 압도적으로 많았다\n",
    "\n",
    "    - train의 경우 492/506, dev의 경우 100/102\n",
    "    - 이를 구문 구조의 output이 나오도록 강제시켜주는 것이 일반화에 도움을 줄 수 있어보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def output_semantic_structure_statistics(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print the statistics of the semantic structure of the output.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame of the data.\n",
    "    \"\"\"\n",
    "    # Copy the DataFrame\n",
    "    df = deepcopy(df)\n",
    "\n",
    "\n",
    "    # Check the speakers in the output\n",
    "    speakers_in_output = df.apply(lambda row: not ((row['speakers'][0]) in row['output'] and (row['speakers'][1] in row['output'])), axis=1)\n",
    "    print('The number of samples that Speakers are not in the output:', speakers_in_output.sum())\n",
    "\n",
    "\n",
    "    # Split outputs into sentences by '.'\n",
    "    sentences = df['output'].apply(lambda x: x.split('.'))\n",
    "\n",
    "\n",
    "    # join the sentences without a first sentence\n",
    "    df['output'] = sentences.apply(lambda x: ' '.join(x[1:]))\n",
    "\n",
    "\n",
    "    # sort the speakers name\n",
    "    df['speakers'] = df['speakers'].apply(lambda x: sorted(x))\n",
    "\n",
    "\n",
    "    # Check the first indexes of the two speakers and the speaker1 - speaker2 order in the output \n",
    "    correct_order_sample = df.apply(lambda row: row['output'].find(row['speakers'][0]) < row['output'].find(row['speakers'][1]), axis=1)\n",
    "    print('The number of samples that the order of the speakers is (speaker1 - speaker2) :', correct_order_sample.sum(), '/', len(df))\n",
    "\n",
    "\n",
    "    # check the starter speaker of the conversation is the first speaker in the output\n",
    "    def compare_starter_speaker_is_first_speaker(row):\n",
    "        starter_speaker = row['conversation'][0]['speaker']\n",
    "        output = row['output']\n",
    "        if row['output'].find(row['speakers'][0]) < row['output'].find(row['speakers'][1]):\n",
    "            # When the order of the speakers is (speaker1 - speaker2)\n",
    "            return True\n",
    "        else:\n",
    "            # When the order of the speakers is (speaker2 - speaker1)\n",
    "            # Check the starter speaker is the second speaker\n",
    "            # If the starter speaker is the second speaker, return True else False\n",
    "            if starter_speaker == row['speakers'][1]:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    starter_speaker_is_first_speaker = df.apply(compare_starter_speaker_is_first_speaker, axis=1)\n",
    "    print('The number of samples that the starter speaker is the first speaker in the output:', starter_speaker_is_first_speaker.sum(), '/', len(df))\n",
    "\n",
    "    # Sample indexes that The starter speaker is not the first speaker in the output\n",
    "    print('Sample indexes that The starter speaker is not the first speaker in the output:',\n",
    "          df[~starter_speaker_is_first_speaker].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples that Speakers are not in the output: 0\n",
      "The number of samples that the order of the speakers is (speaker1 - speaker2) : 328 / 506\n",
      "The number of samples that the starter speaker is the first speaker in the output: 492 / 506\n",
      "Sample indexes that The starter speaker is not the first speaker in the output: [31, 32, 33, 62, 96, 110, 141, 304, 305, 323, 328, 335, 336, 475]\n"
     ]
    }
   ],
   "source": [
    "output_semantic_structure_statistics(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples that Speakers are not in the output: 0\n",
      "The number of samples that the order of the speakers is (speaker1 - speaker2) : 73 / 102\n",
      "The number of samples that the starter speaker is the first speaker in the output: 100 / 102\n",
      "Sample indexes that The starter speaker is not the first speaker in the output: [81, 83]\n"
     ]
    }
   ],
   "source": [
    "output_semantic_structure_statistics(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### speaker1의 요약 내용과, spekaer2의 요약 내용의 길이를 각각 확인 \n",
    "    \n",
    "- 각 인물의 발화 내용 길이와 요약 내용의 길이 간의 상관관계 파악\n",
    "    - 만약 길이에 따라 늘어난다면, 실제 학습된 모델도 그러하는지 파악\n",
    "    - 만약 길이가 항상 고정된다면, 그에 따른 prompt 추가 및 추가 아이디어 생각 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output 구조에 맞게 모델이 내뱉도록 하기 위해 할 수 있는 것들\n",
    "\n",
    "- **prompt를 구성한다**\n",
    "    - 예를 들어, \"요약을 하는데 맨 첫 문장은 전반적인 대화에 대한 요약, 이어서 'speaker 1은 ~~' 형태의 여러개의 문장, 마지막으로 'speaker 2는 ~' 형태의 여러개의 문장으로 작성해줘'\n",
    "\n",
    "</br>\n",
    "\n",
    "- **대화 내역의 노이즈를 없앤 후 모델에 전달한다**\n",
    "    - 대화 내역과 output 간의 상관관계를 파악하여 필요한 feature들과 불필요한 feautre들을 파악하고\n",
    "    - 필요한 feature들만 남겨 모델의 입력으로 사용한다\n",
    "\n",
    "</br>\n",
    "\n",
    "- **최대 길이에 의해 짤리는 부분을 완전히 없앤다**\n",
    "    - 모델이 맨 마지막 지시(instruction)에 해당하는 부분의 토큰까지 모두 입력으로 받아낼 수 있도록 \n",
    "    - 최대 길이를 조절하던지, 앞선 방식으로 입력을 줄여서 사용한다\n",
    "\n",
    "</br>\n",
    "\n",
    "- **lost in the middle 문제가 발생하는지 파악하고 이를 해결한다**\n",
    "    - 대화 내역이 워낙 길다 보니까, 중간에 해당하는 부분이 제대로 요약되고 있는지를 validation dataset에 대해 평가한다\n",
    "    - 만약 제대로 요약되지 않고 있다면, 이를 해결하기 위해 \n",
    "        - 앞서 분석한 요약에 별로 쓸모가 없는 문장들을 중간에 배치하고\n",
    "        - 중요한 문장을 앞 뒤에 배치함으로써 해결한다\n",
    "\n",
    "<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
