{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_empty_utterance(data:json):\n",
    "#     \"\"\"\n",
    "#     Remove empty utterances from the data\n",
    "#     \"\"\"\n",
    "#     for example in data:\n",
    "#         example['input']['conversation'] = [cvt for cvt in example['input']['conversation'] if cvt['utterance'] != '']\n",
    "#     return data\n",
    "# 최종 단계에서 if utterance = \"\" 하면 되는 거여서 굳이 함수로 만들 필요 없음\n",
    "\n",
    "def correct_wrong_output(data:json, path:str):\n",
    "    \"\"\"\n",
    "    1. Correct wrong speakers in outputs of train samples 'train-000401', 'train-000402, 'train-000111'\n",
    "    2. Add dot(.) at the end of the last sentence in outputs of train samples 'train-000130'\n",
    "    4. Replace speaker name 'SSD' with 'SD' in outputso of 'train-000030', 'train-000193' and 'dev-000085'\n",
    "    5. Remove duplicate sentences in outputs of dev samples 'dev-000093'.\n",
    "    \"\"\"\n",
    "    if 'train' in path:\n",
    "        # Correct wrong speakers\n",
    "        data[400]['output'] = data[400]['output'].replace('SD2100504','SD2110504')\n",
    "        data[401]['output'] = data[401]['output'].replace('SD2110503','SD2100503')\n",
    "        data[110]['output'] = data[110]['output'].replace('SD20010813','SD2001083')\n",
    "        # Add dot(.) at the end of the last sentence\n",
    "        data[129]['output'] = data[129]['output'] + '.'\n",
    "        # Replace speaker name\n",
    "        data[29]['output'] = data[29]['output'].replace('SSD', 'SD')\n",
    "        data[192]['output'] = data[192]['output'].replace('SSD', 'SD')\n",
    "\n",
    "    elif 'dev' in path:\n",
    "        # Replace speaker name\n",
    "        data[84]['output'] = data[84]['output'].replace('SSD', 'SD')\n",
    "        # Remove duplicate sentences\n",
    "        data[92]['output'] = '.'.join(data[92]['output'].split('.')[1:]).strip()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_space_after_period_and_remove_control_characters(data:json, path:str):\n",
    "    \"\"\"\n",
    "    Add space after period if there is no space after period\n",
    "    text = re.sub(r'\\.(?=\\S)', '. ', text)\n",
    "    \"\"\"\n",
    "    if 'train' or 'dev' in path:\n",
    "        # Add space after period in utterances\n",
    "        for example in data:\n",
    "            example['input']['conversation'] = [{'speaker': cvt['speaker'], 'utterance': re.sub(r'\\.(?=\\S)', '. ', cvt['utterance']).strip()} for cvt in example['input']['conversation']]\n",
    "\n",
    "        # Remove_control_characters and Add space after period in outputs\n",
    "        for example in data:\n",
    "            output = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', example['output'])\n",
    "            example['output'] = re.sub(r'\\.(?=\\S)', '. ', output).strip()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def change_weird_output(data:json, path:str):\n",
    "    \"\"\"\n",
    "    Standardize the type of the output of train-000032, train-000418, dev-000074, dev-000093\n",
    "    \"\"\"\n",
    "    # Standardize the type of outputs\n",
    "    if 'train' in path:\n",
    "        # train-000032 : total_summary 교체\n",
    "        output = data[31]['output'].split('.')\n",
    "        total_summary = \"두 화자는 이 대화에서 진로 관련 고민에 대해 이야기했습니다. \"\n",
    "        data[31]['output'] = total_summary + '.'.join(output[1:])\n",
    "\n",
    "        # train-000418 : total_summary 추가\n",
    "        total_summary = \"두 화자는 이 대화에서 다이어트에 대해 이야기했습니다. \"\n",
    "        data[417]['output'] = total_summary + data[417]['output']\n",
    "\n",
    "\n",
    "    elif 'dev' in path:\n",
    "        # dev-000074 : total_summary 수정\n",
    "        data[73]['output'] = \"두 화자는 \"+ data[73]['output'] # 이 대화에서 -> 두 화자는 이 대화에서\n",
    "\n",
    "        # dev-000093 : total_summary 추가\n",
    "        total_summary = \"두 화자는 이 대화에서 엔시티와 방탄소년단에 대해 이야기 했습니다. \"\n",
    "        data[92]['output'] = total_summary + data[92]['output']\n",
    "    \n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_sd_in_total_summary(data:json, path:str):\n",
    "    \"\"\"\n",
    "    Remove 'SD' in total_summary of train-000020 and train-000176\n",
    "    \"\"\"\n",
    "    if 'train' in path:\n",
    "        # train-000020 : total_summary 수정\n",
    "        data[19]['output'] = data[19]['output'].replace('SD2000039의 꿈인 ','')\n",
    "\n",
    "        # train-000176 : total_summary '.' 가 빠져있던 것을 수정\n",
    "        output = data[175]['output']\n",
    "        data[175]['output'] = re.sub(r'(장단점에 대해 말했습니다)\\s+(SD\\d{7}(?:은|는))', r'\\1. \\2', output)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def total_summary_generalization(data:json, path:str):\n",
    "    \"\"\"\n",
    "    Standardize the format of the total summary in the first sentence of the output \n",
    "    to start with \"두 화자는 이 대화에서\".\n",
    "    \"\"\"\n",
    "    types = [\"두 화자는\", \"화자들은\" ,\"두 사람은\", \"이 대화에서는\"] # \"두 화자는 이 대화에서\"\n",
    "    types2 = r\"SD\\d{7}(?:와|과).*SD\\d{7}(?:은|는)\"\n",
    "\n",
    "    if 'train' or 'dev' in path:\n",
    "        for example in data:\n",
    "            output = example['output']\n",
    "            total_summary = output.split('.')[0]\n",
    "\n",
    "            if \"두 화자는 이 대화에서\" in total_summary:\n",
    "                continue\n",
    "            elif re.search(types2, total_summary):\n",
    "                total_summary = re.sub(r'(.*)'+types2, '두 화자는 이 대화에서', total_summary)+'.'\n",
    "                example['output'] = total_summary+'.'.join(output.split('.')[1:])\n",
    "            else:\n",
    "                for type in types:\n",
    "                    if type in total_summary:\n",
    "                        total_summary = re.sub(r'(.*)'+type, '두 화자는 이 대화에서', total_summary)+'.'\n",
    "                        example['output'] = total_summary+'.'.join(output.split('.')[1:])\n",
    "                        break\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_pattern = [r'\\w~', r'\\b으\\b', r'\\b그\\b', r'\\b뭐\\b', r'\\b어\\b',  r'\\b인제\\b', r'\\b이제\\b', r'\\b막\\b', r'\\b아\\b', r'\\b음\\b', r'\\b읍\\b', r'\\b오\\b', r'\\b으\\b'] \n",
    "\n",
    "    # 커스텀 불용어 제거\n",
    "    for pattern in stopwords_pattern:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # x를 포함한 단어 제거\n",
    "    text = re.sub(r'\\b[가-힣a-zA-Z]*[xX][가-힣a-zA-Z]*\\b', '', text)\n",
    "\n",
    "    # 단어가 두 번 이상 반복되는 경우 -> 1개로\n",
    "    # text = re.sub(r'\\b(\\w)\\s+\\1\\b', r'\\1', text)\n",
    "    # text = re.sub(r'\\b([가-힣a-zA-Z0-9_]+)\\s+\\1\\b', r'\\1', text)\n",
    "    text = re.sub(r'\\b(\\w+)\\b(?:\\s+\\1\\b)+', r'\\1', text)\n",
    "\n",
    "    # 공백 두 번 이상 연속 -> 1개로\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # 간단한 후처리\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess(path:str):\n",
    "    \n",
    "    # Load the dataset\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # correct_wrong_output\n",
    "    data = correct_wrong_output(data, path)\n",
    "\n",
    "    # change_weird_output\n",
    "    data = change_weird_output(data, path)\n",
    "\n",
    "    # remove_sd_in_total_summary\n",
    "    data = remove_sd_in_total_summary(data, path)\n",
    "\n",
    "    # add_space_after_period and strip\n",
    "    data = add_space_after_period_and_remove_control_characters(data, path)\n",
    "    \n",
    "    # total_summary_generalization\n",
    "    data = total_summary_generalization(data, path)\n",
    "\n",
    "    # # remove_empty_utterance\n",
    "    # data = remove_empty_utterance(data)\n",
    "\n",
    "    # preprocess the dataset\n",
    "    for example in data:\n",
    "        for cvt in example['input']['conversation']:\n",
    "            cvt['utterance'] = remove_stopwords(cvt['utterance'])\n",
    "\n",
    "    # Save the preprocessed dataset\n",
    "    with open(path.split('/')[-1].split('_')[1].split('.')[0]+'.json', 'w') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Preprocessing of {path} is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of ../resource/data/일상대화요약_train.json is done!\n"
     ]
    }
   ],
   "source": [
    "preprocess('../resource/data/일상대화요약_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of ../resource/data/일상대화요약_dev.json is done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of ../resource/data/일상대화요약_test.json is done!\n"
     ]
    }
   ],
   "source": [
    "preprocess('../resource/data/일상대화요약_dev.json')\n",
    "preprocess('../resource/data/일상대화요약_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
