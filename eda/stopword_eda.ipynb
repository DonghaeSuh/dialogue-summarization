{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword들을 찾고 제거하거나 1개로 통일하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 양 옆에 공백을 두고 있지만 의미없는 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a json file and return a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): Path to the json file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame of the json file.\n",
    "    \"\"\"\n",
    "    # Read the json file\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    # columns = ['id', 'conversation', 'subject_keyword', 'output']\n",
    "    df = pd.DataFrame(data)\n",
    "    df['conversation'] = df['input'].apply(lambda x: x['conversation'])\n",
    "    df['subject_keyword'] = df['input'].apply(lambda x: x['subject_keyword'])\n",
    "\n",
    "    # Drop the 'input' column\n",
    "    df.drop('input', axis=1, inplace=True)\n",
    "\n",
    "    # Speakers in the conversation\n",
    "    df['speakers'] = df['conversation'].apply(lambda turns: list(set(turn['speaker'] for turn in turns)))\n",
    "\n",
    "    # Reorder the columns\n",
    "    df = df[['id', 'conversation', 'subject_keyword', 'speakers', 'output']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_dataframe('../resource/data/일상대화요약_train.json')\n",
    "dev_df = make_dataframe('../resource/data/일상대화요약_dev.json')\n",
    "test_df = make_dataframe('../resource/data/일상대화요약_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the stopwords\n",
    "def find_stopwords(df: pd.DataFrame, pattern) -> set:\n",
    "    \"\"\"\n",
    "    Find the stopwords in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame of the json file.\n",
    "\n",
    "    Returns:\n",
    "    set: Set of stopwords.\n",
    "    \"\"\"\n",
    "    # Find the stopwords\n",
    "    stopwords = defaultdict(int)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for turn in row['conversation']:\n",
    "            utterance = turn['utterance']\n",
    "\n",
    "            # Find the stopwords and add them to stopwords\n",
    "            stopwords_list = re.findall(pattern, utterance)\n",
    "            for stopword in stopwords_list:\n",
    "                stopwords[stopword] += 1\n",
    "\n",
    "    # Make a Series of stopwords\n",
    "    stopwords = pd.Series(stopwords)\n",
    "\n",
    "    print(f\"Number of stopwords: {len(stopwords)}\")\n",
    "\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = find_stopwords(train_df, pattern = r'(?:\\s+[가-힣]{1}\\s+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 거     5283\n",
       " 뭐     4345\n",
       " 그     4264\n",
       " 좀     2492\n",
       " 안     2460\n",
       " 또     2343\n",
       " 게     2236\n",
       " 한     1729\n",
       " 때     1435\n",
       " 막     1396\n",
       " 잘     1281\n",
       " 다     1269\n",
       " 더     1052\n",
       " 수      881\n",
       " 어      801\n",
       " 못      768\n",
       " 할      755\n",
       " 해      699\n",
       " 걸      668\n",
       " 것      627\n",
       " 이      601\n",
       " 아      589\n",
       " 건      530\n",
       " 내      509\n",
       " 나      434\n",
       " 난      349\n",
       " 가      325\n",
       " 될      317\n",
       " 꼭      310\n",
       " 참      305\n",
       " 왜      301\n",
       " 갈      290\n",
       " 딱      285\n",
       " 제      273\n",
       " 데      270\n",
       " 저      249\n",
       " 몇      242\n",
       " 본      241\n",
       " 두      229\n",
       " 큰      220\n",
       " 볼      212\n",
       " 사      170\n",
       " 너      162\n",
       " 줄      154\n",
       " 된      154\n",
       " 네      135\n",
       " 뭘      135\n",
       " 살      133\n",
       " 날      133\n",
       " 원      132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found in '그래 그래서': 그래 그래서\n",
      "Match found in '아니 아니야': 아니 아니야\n",
      "Match found in '하지 하지만': 하지 하지만\n",
      "No match found in '먹먹 먹'\n",
      "Match found in '그래 그래': 그래 그래\n",
      "Match found in '응 응해': 응 응해\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 테스트 문자열들\n",
    "texts = [\n",
    "    \"그래 그래서\",   # 매칭됨\n",
    "    \"아니 아니야\",   # 매칭됨\n",
    "    \"하지 하지만\",   # 매칭됨\n",
    "    \"먹먹 먹\",       # 매칭되지 않음\n",
    "    \"그래 그래\",     # 매칭되지 않음\n",
    "    \"응 응해\",       # 매칭됨\n",
    "]\n",
    "\n",
    "# 정규 표현식 패턴\n",
    "pattern = r'\\b([가-힣]+)\\s+\\1[가-힣]*\\b'\n",
    "\n",
    "# 각 문자열에 대해 패턴과 일치하는지 확인\n",
    "for text in texts:\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        print(f\"Match found in '{text}':\", match.group())\n",
    "    else:\n",
    "        print(f\"No match found in '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = find_stopwords(train_df, pattern = r'\\b([가-힣]+)\\s+\\1([가-힣]+\\b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "아  니      4\n",
       "하  고      4\n",
       "그  거      4\n",
       "이  게      4\n",
       "그  냥      4\n",
       "   거를     4\n",
       "어  떻게     4\n",
       "그  렇게     4\n",
       "   러니까    4\n",
       "아  직      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.sort_values(ascending=False, inplace=True)\n",
    "sw[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('그래', '서'), ('거인이었', '거든요')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b([가-힣]+)\\s+\\1([가-힣]+)\\b' ,'그래 그래서 애니메이션이 진격의 거인이었 거인이었거든요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그래 애니메이션이 진격의 거인이었.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\b([가-힣]+)\\s+\\1([가-힣]*)\\b', r'\\1','그래 그래서 애니메이션이 진격의 거인이었 거인이었거든요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: '그래 그래서' => Modified: '그래서'\n",
      "Original: '아니 아니야' => Modified: '아니야'\n",
      "Original: '하지 하지만' => Modified: '하지만'\n",
      "Original: '먹먹 먹' => Modified: '먹먹 먹'\n",
      "Original: '그래 그래' => Modified: '그래 그래'\n",
      "Original: '응 응해' => Modified: '응해'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 테스트 문자열들\n",
    "texts = [\n",
    "    \"그래 그래서\",   # 매칭됨\n",
    "    \"아니 아니야\",   # 매칭됨\n",
    "    \"하지 하지만\",   # 매칭됨\n",
    "    \"먹먹 먹\",       # 매칭되지 않음\n",
    "    \"그래 그래\",     # 매칭되지 않음\n",
    "    \"응 응해\",       # 매칭됨\n",
    "]\n",
    "\n",
    "# 정규 표현식 패턴\n",
    "pattern = r'\\b([가-힣]+)\\s+\\1([가-힣]+)\\b'\n",
    "\n",
    "# 각 문자열에 대해 패턴과 일치하는지 확인하고 치환\n",
    "for text in texts:\n",
    "    result = re.sub(pattern, r'\\1\\2', text)\n",
    "    print(f\"Original: '{text}' => Modified: '{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X를 포함하는 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xxx          4\n",
       "xx로          1\n",
       "x           28\n",
       "x는           2\n",
       "제x           1\n",
       "다니x          1\n",
       "즐겁더라고x       1\n",
       "xx케          1\n",
       "x케           1\n",
       "xx          15\n",
       "요즘x          1\n",
       "어디xx         1\n",
       "요x           1\n",
       "이x           3\n",
       "마마마마x        1\n",
       "근x           1\n",
       "싶x           1\n",
       "생각xx         1\n",
       "알았x          1\n",
       "같x           2\n",
       "운x을          1\n",
       "그x           2\n",
       "같으xx요        1\n",
       "그래x          1\n",
       "왜x면          1\n",
       "그xx          1\n",
       "x이지만         1\n",
       "그래갖고서x       1\n",
       "먹x           1\n",
       "그x고          1\n",
       "끊x고          1\n",
       "x다음에         1\n",
       "xx서          6\n",
       "한x           1\n",
       "x번           1\n",
       "xx으로         1\n",
       "올라x고         1\n",
       "x보적으로        1\n",
       "아이x          1\n",
       "xxxxx습니다     1\n",
       "x거           1\n",
       "xx도          1\n",
       "x짜           1\n",
       "무난했xx        1\n",
       "xxxx         2\n",
       "x데           4\n",
       "그x까          1\n",
       "같xx          1\n",
       "xx게          1\n",
       "x시           1\n",
       "해x고          1\n",
       "꼽으라x         1\n",
       "x니까          4\n",
       "x게           1\n",
       "xx까          1\n",
       "싶xx          1\n",
       "지난xx         1\n",
       "xx튼          1\n",
       "x까           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_stopwords(test_df, pattern = r'\\b[가-힣a-zA-Z]*[xX][가-힣a-zA-Z]*\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
