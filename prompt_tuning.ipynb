{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78eeb058187c4f7087ecd85d354d9d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a844d00c0b645a3b301343416d0692d",
              "IPY_MODEL_dbfe551f689b42bfa558716927415b87",
              "IPY_MODEL_0707e6640cd94e1dbb1f5b00570ee4f6"
            ],
            "layout": "IPY_MODEL_08f5838cfdde418f84abea7667503b94"
          }
        },
        "1a844d00c0b645a3b301343416d0692d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a837b65e3ca4bdba8b7ba81d4bb6e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_daf92d5152c1468ba5e8311616c7272f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dbfe551f689b42bfa558716927415b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae08ac57c8d148e0a17b0cc588ee23a5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19f7cb46fbc245d6909af10fca16ae24",
            "value": 4
          }
        },
        "0707e6640cd94e1dbb1f5b00570ee4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b1bd5e0a9d44099ef488b1a4b7e048",
            "placeholder": "​",
            "style": "IPY_MODEL_24087c5c2eb04af7a8ce3280ea05e8b9",
            "value": " 4/4 [00:05&lt;00:00,  1.15s/it]"
          }
        },
        "08f5838cfdde418f84abea7667503b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a837b65e3ca4bdba8b7ba81d4bb6e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf92d5152c1468ba5e8311616c7272f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae08ac57c8d148e0a17b0cc588ee23a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f7cb46fbc245d6909af10fca16ae24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b1bd5e0a9d44099ef488b1a4b7e048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24087c5c2eb04af7a8ce3280ea05e8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt tuning"
      ],
      "metadata": {
        "id": "p46MTBIf3o7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsrPh5pR382g",
        "outputId": "8bd1a929-7fc3-43ec-eff5-4249bc116f6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from torch.utils.data import Dataset\n",
        "import tqdm\n",
        "import json\n",
        "import re\n",
        "from peft import PeftModel"
      ],
      "metadata": {
        "id": "MZjszGZw35Bz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/dialouge_summarization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cC-YbpR4-ga",
        "outputId": "6114c951-33f3-40c8-d812-a56ecbe2676f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dialouge_summarization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 불러오기\n",
        "\n",
        "- Version 1. baseline 모델\n",
        "- Version 2. baseline 모델 + fine-tuning"
      ],
      "metadata": {
        "id": "dkFJFAfS4ng0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = 2\n",
        "model_id = 'MLP-KTLim/llama-3-Korean-Bllossom-8B'\n",
        "device = 'cuda:0'\n",
        "adapter_checkpoint_path = './resource/results/checkpoint-62/'\n",
        "output = 'test_results.json'"
      ],
      "metadata": {
        "id": "yemA9P0W5QYa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## loading model ##\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=device,\n",
        "        # return_dict=True,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "\n",
        "if version == 2:\n",
        "    model = PeftModel.from_pretrained(model, adapter_checkpoint_path)\n",
        "    model = model.merge_and_unload()\n",
        "    model.to(dtype = torch.bfloat16)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "## loading tokenizer ##\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "terminators = [tokenizer.eos_token_id,tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "78eeb058187c4f7087ecd85d354d9d54",
            "1a844d00c0b645a3b301343416d0692d",
            "dbfe551f689b42bfa558716927415b87",
            "0707e6640cd94e1dbb1f5b00570ee4f6",
            "08f5838cfdde418f84abea7667503b94",
            "6a837b65e3ca4bdba8b7ba81d4bb6e2d",
            "daf92d5152c1468ba5e8311616c7272f",
            "ae08ac57c8d148e0a17b0cc588ee23a5",
            "19f7cb46fbc245d6909af10fca16ae24",
            "c1b1bd5e0a9d44099ef488b1a4b7e048",
            "24087c5c2eb04af7a8ce3280ea05e8b9"
          ]
        },
        "id": "avK9ghbO4ydS",
        "outputId": "8bfb8c9f-1132-4b80-99b7-d936fd029d86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78eeb058187c4f7087ecd85d354d9d54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예시 데이터 불러오기\n",
        "\n",
        "- 10개의 샘플 데이터에 대해 prompt 튜닝시 모델의 출력이 어떻게 바뀌는지 확인"
      ],
      "metadata": {
        "id": "-2I_ULDW3sAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_prompt = '''You are a helpful AI assistant. Please answer the user's questions kindly.\n",
        "당신은 유능한 AI 어시스턴트 입니다. 사용자의 질문에 대해 친절하게 답변해주세요.'''"
      ],
      "metadata": {
        "id": "b-0A-YWm6fnM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, fname, tokenizer):\n",
        "        IGNORE_INDEX=-100\n",
        "        self.inp = []\n",
        "        self.label = []\n",
        "\n",
        "        PROMPT = pre_prompt\n",
        "\n",
        "        with open(fname, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        def make_chat(inp):\n",
        "            chat = [\"[Conversation]\"]\n",
        "            for cvt in inp['conversation']:\n",
        "                speaker = cvt['speaker']\n",
        "                utterance = cvt['utterance']\n",
        "                chat.append(f\"화자{speaker}: {utterance}\")\n",
        "            chat = \"\\n\".join(chat)\n",
        "\n",
        "            speakers = list(set(re.findall(r'SD\\d{7}', chat)))\n",
        "\n",
        "            question =  f'''[Question]\\n위 {', '.join(inp['subject_keyword'])} 주제에 대한 대화를 다음과 같은 순서로 요약해주세요.\n",
        "            \\n 맨 첫번째 문장은 전반적인 요약이 담겨있어야 하고, 이어서 속에 {speakers[0]}가 말한 모든 내용을 여러 문장으로 요약하고, 마지막으로 Conversation 속에 {speakers[1]}가 말한 모든 내용을 여러 문장으로 요약해주세요.\n",
        "            \\n [{speakers[0]}의 말 요약]처럼 소제목을 사용하지 말고\n",
        "            \\n 단순하게 여러 문장을 '.' 기준으로 이어붙인 구조로 답변해주세요.''' # post_prompt\n",
        "            chat = chat + \"\\n\\n\" + question\n",
        "\n",
        "            return chat\n",
        "\n",
        "        for example in data:\n",
        "            chat = make_chat(example[\"input\"])\n",
        "            message = [\n",
        "                {\"role\": \"system\", \"content\": PROMPT},\n",
        "                {\"role\": \"user\", \"content\": chat},\n",
        "            ]\n",
        "\n",
        "            source = tokenizer.apply_chat_template(\n",
        "                message,\n",
        "                add_generation_prompt=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "            target = example[\"output\"]\n",
        "            if target != \"\":\n",
        "                target += tokenizer.eos_token\n",
        "            target = tokenizer(target,\n",
        "                      return_attention_mask=False,\n",
        "                      add_special_tokens=False,\n",
        "                      return_tensors=\"pt\")\n",
        "            target[\"input_ids\"] = target[\"input_ids\"].type(torch.int64)\n",
        "\n",
        "            input_ids = torch.concat((source[0], target[\"input_ids\"][0]))\n",
        "            labels = torch.concat((torch.LongTensor([IGNORE_INDEX] * source[0].shape[0]), target[\"input_ids\"][0]))\n",
        "            self.inp.append(input_ids)\n",
        "            self.label.append(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inp)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inp[idx]"
      ],
      "metadata": {
        "id": "Ck33Hqhj6P0x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(\"resource/data/일상대화요약_test.json\", tokenizer)[:10]"
      ],
      "metadata": {
        "id": "Bz2Tdgvw5Ls4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "8bPFzX_-7FYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"resource/data/일상대화요약_test.json\", \"r\") as f:\n",
        "    result = json.load(f)\n",
        "\n",
        "for idx in tqdm.tqdm(range(len(dataset))):\n",
        "    inp = dataset[idx]\n",
        "    outputs = model.generate(\n",
        "        inp.to(device).unsqueeze(0),\n",
        "        max_new_tokens=1024,\n",
        "        eos_token_id=terminators,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "        no_repeat_ngram_size= 5, # prevent repeated sentences\n",
        "        # num_beams = 4\n",
        "    )\n",
        "\n",
        "    result[idx][\"output\"] = tokenizer.decode(outputs[0][inp.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "with open(output, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(json.dumps(result, ensure_ascii=False, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Pm5Lpe5zSs",
        "outputId": "4dc48c7a-b5e3-48c2-8c7b-af0315cbb9f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|██████████| 10/10 [03:42<00:00, 22.25s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이전 결과와 비교"
      ],
      "metadata": {
        "id": "-2BJX7a07iN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev_result_path = 'result.json'\n",
        "post_result_path = 'test_results.json'"
      ],
      "metadata": {
        "id": "yddlmIdi7ryf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(prev_result_path, \"r\") as f:\n",
        "    prev_result = json.load(f)\n",
        "\n",
        "with open(post_result_path, \"r\") as f:\n",
        "    post_result = json.load(f)\n",
        "\n",
        "\n",
        "for idx in tqdm.tqdm(range(len(dataset))):\n",
        "    prev_output = prev_result[idx][\"output\"]\n",
        "    post_output = post_result[idx][\"output\"]\n",
        "    print(f\"\\n [[Sample {idx} ]] \\n\\n <<prev_output>> \\n {prev_output} \\n\\n <<post_output>> \\n {post_output} \\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvZIGYAE7k9e",
        "outputId": "bc60e07b-2b14-47c7-e3f1-7f17b5386458"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 5032.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " [[Sample 0 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000044는 여름에 팥빙수를 자주 먹으며, 특히 설빙의 초코 빙수를 좋아한다고 말했습니다. 초코와 딸기, 오레오 등 초코 관련 빙수도 좋아한다고 덧붙였습니다. SD2000045는 여름 과일 중 복숭아와 수박을 좋아하며, 여름을 기다리는 이유는 수박을 먹고 티브이를 보며 추억을 만드는 것이라고 말했습니다. 또한, 추운 날에는 아이스 음료를 좋아한다고 하였고, SD2000044는 추울 때 아이스크림을 먹으면 기분이 좋다고 말했습니다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000045는 여름에 과일을 많이 먹는 스텀일이라고 말했어요. 봄에서 여울 넘어갈 때 과일이 비싸지 않아서 그때는 복숭아와 수박을 많이 먹는다고 했어요. 여름을 기다리는 이유는 수박을 먹고 티비를 보면서 추억을 만들기 때문이라고 말했어요.\n",
            "\n",
            "SD2000044는 여름에 먹은 음식에 대해 말했어요. 팥빙수를 많이 먹는다고 말했어요. 설빙에서 초코 빙수를 가장 좋아하는데 초코와 딸기, 오레오 같은 초코 관련 빙수도 좋아해요. 초코를 많이 좋아하는 편이라고 말했어요.\n",
            "SD2000044가 여름에 팟빙수를 많이 안 먹는다고 말한 name1 님과 달리 팥빙수를 좋아하는 것 같아요. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 1 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " 이 대화는 크리스마스, 추석, 설날에 대한 대화를 요약한 내용입니다.\n",
            "\n",
            "**크리스마스**\n",
            "- **name1 님**: 크리스마스에는 크리스마스 특유의 분위기와 캐럴이 좋아. 특별한 계획은 없지만 집에서 친구들과 놀거나 아르바이트를 하며 평소와 똑같이 보내지만 좋은 추억이 있다.\n",
            "- **name2 님**: 크리스마스에는 캐럴과 따뜻한 분위기가 좋아. 크리스마스에는 특별한 계획은 없지만 집에서 놀거나 남포동에서 놀거나 아르바이트를 하며 평소와 똑같이 보내지만 좋은 추억이 있다.\n",
            "\n",
            "**추석**\n",
            "- **name1 님**: 어릴 때는 친척들이랑 만나서 재미있게 놀다가 헤어질 때가 무서워서 가고 싶지 않았지만, 이제는 친척들을 한두 번 만날 수 있어서 기다려진다.\n",
            "- **name2 님**: 추석은 맛있는 음식과 오랜만에 만나는 친척과 외갓집 분들 때문에 좋아. 친척과 외갓집 분들이 달라져 보이는 모습을 보며 재밌는 추억이 있다.\n",
            "\n",
            "**설날**\n",
            "- **name1 님**: 최근에는 설날에 친척들을 거의 보지 못했지만, 강원도에 외할머니가 있어서 가고 싶었지만 일이 있어서 못 가는 일이 많다. 설날에 대한 추억이 아쉬운 추억 밖에 없다.\n",
            "- **name2 님**: 설날도 추석과 비슷한 느낌으로 좋아하는 것 같다. 설날에는 새롭고 맛있는 음식과 오랜만에 보는 분들이 많아 좋다. 설날이 1년에 한 번 밖에 없어서 소중하게 여겨진다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000045는 크리스마스에는 크리스마스가 기념일로 기다려지는 행사라고 말했습니다. 크리스마스는 춥지만 분위를 따뜻하고 모든 사람들이 행복해 보이는 표정을 짓으며 웃으며 케이크를 먹으며 맛있는 음식을 즐기는 따뜻하고 활기찬 분위기를 좋아합니다. 크리마스에는 캐럴과 특유의 분위기가 너무 좋아서 크리스마스 생각하면 두근거리는 느낌이 있습니다. 크리스마스를 기다리면서 특별하게 할 일은 없지만 집에서 놀거나 친구들과 놀거나 아르바이트를 하며 평소와 똑같이 보내지만 크리스마스라서 좋은 것 같다고 말했습니다. 추석은 어릴 때는 친척들이 많이 모여서 재미있게 노는 것 같지만 헤어질 때는 무서워서 가고 싶지 않았지만, 이제는 친척들을 한두 번 만나는 게 많지 않아서 추석을 기다리며 할머니를 볼 기분이 들고 기분이 좋다고 말했습니다. 설날은 최근에 친척들을 보지 못했기 때문에 설날에 대한 기억이 아쉬운 것 같다고 말했고, 강원도 외할머니 집에 가는 것이 꿈이었지만 일이 있어서 못 가서 아쉬운 추험이 많다고 말했습니다.\n",
            "\n",
            "SD2000044는 크리스마스는 캐럴과 특수한 분위기가 좋아서 크리스马스 생각하면 두 근거리는 느낌을 받지만 특별하게 할 일 없이 집에서 놀거나 아르바이트를 하며 평상시와 똑같게 보내지만 크리스 마스라서 좋은 거 같다고 말했습니다 크리스마스도 크리스마스를 좋아합니다. 크림 마스는 캐럴과 크리스마스 분위기가 좋아 크리스마스하면 두근거는 느낌이 있습니다 크리스마스 특별하게 할 일 없지만 집에서 친구들과 놀거나 남포동 가서 놀거나 아르 바이트 하며 평상시에 똑같이 하지만 크리스마스면 좋은 거 같습니다. 추 석은 맛있는 음식이 많고 오랜 만에 만나는 친족과 외갓집 사람들을 만나서 기분이 좋고, 친족이나 외갓집 사람들이 달라져 보이는 모습을 보는 것도 재미있고 어릴 때의 추억이 기억에 남는다고 말했습니다. 그리고 설날은 새롭고 음식이 많이 새롭고 1년에 한 번밖에 안 되니까 소중하게 여기는 거 같습니다. 설 날은 맛있는 음식을 많이 먹고 새로운 오랜 만에 보는 분들을 많이 보고 하니까 좋게 기억 남는 거 같습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 2 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " 화자 SD2000045는 최근에 어 쿠키를 구워서 선물한 경험이 많다고 말했습니다. 그리고 화자 SD2000044는 부모님께 가짜 꽃과 함께 돈을 예쁘게 포장한 상자를 선물한 적이 있다고 말했습니다. 화자 SD2000044는 부모님께 선물을 하면서 돈을 직접 벌어서 선물로 드리는 것이 처음이라서 고민 끝에 가짜 꽃과 함께 돈을 선물한 것에 대해 기억에 남는 선물이라고 말했습니다. 화자 SD2000045는 향수나 향기나는 제품을 선물할 때가 가장 기억에 남는 선물이라고 말했습니다. 또한, 향수는 항상 사람을 기억하거나 분별하게 되기 때문에 선물할 때 가장 먼저 생각하는 선물이라고 말했습니다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000045는 최근에 어 쿠키했던 것들을 많이 선물하고 있다고 말했습니다. 그는 제과제빱을 전공했기 때문에 빵이나 쿠키 같은 것을 만들어서 선물할 때 보람차고 기분이 좋다고 했습니다. 최근에 누군가를 선물한 적이 있냐고 묻자, 최근에 선물을 하거나 받아본 적은 없다고 말했습니다. SD2000044는 최근에 부모님께선물을 드렸다고 말했습니다. 부모님께 큰 돈을 벌어들여서 선물을 드리고자 했고, 돈을 계좌이체하거나 현금을 봉지에 넣어주는 것보다는 선물을 주는 느낌이 나도록 가짜 꽃과 함께 예쁘게 꾸며진 상자를 선물했습니다. 부모님이 좋아하셨다고 말했습니다. 가장 기억에 남은 선물은 향수를 선물했을 때라고 말했습니다. 그는 항상 향수로 사람을 기억하려고 하기 때문에 향수나 향기나는 제품을 선물할 때가 가장 좋다고 했습니다.\n",
            "\n",
            "SD2000044는 부모님에게 선물을 드렸다고 했습니다. 그는 아르바이트로 벌어들인 돈으로 부모님이 좋아하는 것을 선물하고 싶었지만, 어떤 선물을 해야 할지 고민했습니다. 그래서 용돈을 주는 것보다는 선글라스를 주는 것 같아서 가짜 꽃과 돈을 넣은 상자를 선물했더니 부모님이 좋아해주셨다고 말했습니다.\n",
            "\n",
            "SD2000045가 최근에 선물하거나 받은 적은 없다고 했지만, 향수를 선물할 때는 항상 기억에 남는다고 말했습니다. 그는 향수나 향기로 사람을 기억하므로 향수나 향기를 나는 제품을 선물하는 것이 제일 좋다고 했습니다 또한, 친구 생일이 있어서 향수를 선물하기 위해 향수를 사게 됐다고 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 3 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000044는 향수 선물을 받았을 때 기분은 좋았지만, 향수 자체는 기억에 남지 않았다고 말했습니다. 그는 향수보다는 바디미스트나 바디워시를 더 선호하며, 향수 선물은 그 사람의 취향을 잘 알아야 하고 선물해 주면 기분 좋은 선물이라고 생각한다고 말했습니다. \n",
            "\n",
            "SD2000045는 바디미스트 선물이 기억에 남는 선물이라고 말했습니다. 그는 향수보다는 바디미스트를 선호하며, 작년 생일 때 친구가 러쉬 브랜드의 기프트박스를 선물해 주었는데, 그게 제일 기억에 남는 선물이었다고 말했습니다. 그는 향수 선물은 그 사람의 취향을 잘 알아야 하고, 선물해 주면 기분 좋은 선물이라고 생각한다고 말했습니다. \n",
            "\n",
            "또한, SD2000044는 초등학생 때 핸드메이드 초콜릿을 만들고 싶었지만 실패했으며, 이후로도 여러 번 만들려 했지만 실패했기 때문에 특별히 만들어서 주는 선물은 안 한다고 말했습니다. SD2000045는 수제청을 직접 만들어서 감기약으로 선물한 적이 있다고 말했습니다. 그는 수제청 같은 것은 만들기가 어렵지 않지만, 감동받을 수 있을 것 같아 주위 어른들에게 해드리고 싶다고 말했습니다. \n",
            "\n",
            "SD2000044는 친구가 화분 케이크를 만들어준 적이 기억에 남는 선물이라고 말했습니다. 그는 만들어주는 선물은 기분이 좋고, 받는 사람도 고마움을 느낄 수밖에 없다고 생각한다고 말했습니다. \n",
            "\n",
            " <<post_output>> \n",
            " 화자 SD2000045는 향수 선별이 까다롭다고 말했습니다. 작년 생일 선물로 친구가 러쉬 브랜드의 기프트박스를 선물해 주었는데, 그 안에 들어있는 바디미스트와 향수는 향도 좋고 제 취향에 맞아 기억에 남았습니다. 향수 선물 시는 선물자도 선물해 주는 사람의 취향과 선호도를 잘 알아야 한다고 말했습니다. 또한, 제과제빔과 같은 핸드메イド 선물은 제일 기분이 좋고, 수제청을 직접 만들어 선물한 적이 있다고 말했습니다. 수제청은 감기약으로 만들어 선물한 것이고, 만들기 어렵지 않아 누구나 해볼 수 있다고 말했습니다. \n",
            "\n",
            "화자 SD200005은 작년 향수 선물 받은 적이 있는데, 선물 받은 향수는 마음에 들지 않았습니다. 향수는 선물 받은 기분은 좋았지만 향수 자체는 기억에 남지 않았습니다. 저는 향수보다는 다른 바디미스트, 바디워시 같은 제품에 더 신경을 씁니다. 가장 기억에 남은 선물은 바디미스트 선물로, 러쉬 브랜드 기프트박스를 받았습니다. \n",
            "\n",
            "화자 이름을 명시하지 않고 요약하면, 화자 SD2000044는 향수 선글을 받은 적이 있지만 마음에 들지 않았다고 말했습니다. 향수 선물을 선물할 때는 선물자와 선물받는 사람의 취미와 선호도를 잘 고려해야 한다고 말했습니다 또한, 화자 SD는 핸드메이크 선물은 선물하는 사람과 받는 사람 모두에게 기분이 좋게 만드는 선물이라고 말했습니다. 화자 SD는 초등학생 때 친구에게 직접 만든 초콜릿을 주었지만 실패했으며, 이후에도 여러 번 실패를 겪었다고 말했습니다. 가장 기억에 나는 핸드메이즈 선물은 친구가 화분에 케이크를 만들어 준 것이며, 그 선물은 디테일하게 만들어져서 기억에 남았다고 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 4 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " 이 대화는 화자 SD2000044와 SD2000045가 각각 기억에 남는 이벤트나 선물에 대해 이야기하는 내용입니다. \n",
            "\n",
            "화자 SD2000045는 제주도에서 친구들과 함께한 기념일을 기념하기 위해 풍선과 사진을 찍으며 즐거운 시간을 보냈다고 말합니다. 이때 친구들과 함께한 시간이 제일 기억에 남는 것이라고 합니다. 또한, 어릴 때 받았던 선물이나 이벤트에 대해선 기억이 별로 없다고 말하며, 최근에 방송을 보면서 친구들과 함께 독특한 이벤트를 해보고 싶다는 생각이 들었다고 합니다.\n",
            "\n",
            "화자 SD2000044는 초등학생 때 친구들이 학교에서 런닝맨처럼 이벤트를 해준 기억이 제일 기억에 남는다고 말합니다. 친구들이 학교에 가서 벽에 종이 붙여놓고 살구를 바구니에 던지며, 중간에 풍선 터뜨리며 초콜릿을 먹으며 재미있게 놀았던 기억이 가장 기억에 남는 것이라고 합니다. 또한, 어릴 때 받았던 선물이나 이벤트가 소중한 것 같다고 말하며, 최근에는 선물을 받았을 때는 그냥 친구가 갖고 싶은 걸 사줘서 고마운 마음만 들 뿐이라고 합니다. \n",
            "\n",
            "이 두 화자는 각각의 기억에 남는 이벤트나 선물에 대해 이야기하며, 어릴 때 받았던 선물이나 이벤트가 소중하다는 점을 공유합니다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000045는 항상 이벤트보다는 기념일 친구들과 함께하는 시간을 기억에 남긴다고 말했습니다. 최근 제주도 여행을 갔을 때 친구들과 함께 사진을 찍고 이야기를 나누며 좋은 기억을 만들었다고 했습니다. 친구들과 함께 맛있는 음식을 먹으며 좋은 추억을 만들었다고도 말했습니다. 또한, 최근 방송에서 본 박나래의 생일 파티가 인상적이었다고 말하며, 자신도 친구들과 함께 그런 이벤트를 한 번 해보고싶다고 했습니다. \n",
            "\n",
            "SD2000045가 받은 이벤트 중 가장 기억에 남는 것은 제주도 여행 때 친구들과 함께 풍선에 바람 넣고 사진 찍으며 웃었고, 맛있는 음식을 함께 먹으며 좋은 추운 기억을 만들었다는 것입니다. 또한, 최근에 본 박나래 생일에 한혜진과 마마무 화사와 함께 생일 파티한 방송을 보고 친구들과 함께 그런 파티를 한 번 해 보고 싶다고 말했습니다. \n",
            "\n",
            "SD2000054는 어릴 때 받은 이벤트 중 기억에 남는 것이 초등학생 때 친구들이 학교에 혼자 있을 때 이벤트를 해주었던 기억이 있다고 말했습니다. 친구들이 학교에 가서 런닝맨 같은 이벤트를 해주며 재미있게 놀았고, 중간에 풍선 터뜸하고 초콜릿 나오는 이벤트도 해주었으며, 마지막에는 친구들이 나타나 노래 부르고 케이크와 선물을 주며 재미있었던 기억이 가장 기억에 남았다고 말했습니다. \n",
            "\n",
            "어릴 때 받은 선물 중 가장 기억에 나는 것은 없다고 말했지만, 최근에 받은 선물은 그냥 쇼핑몰에서 사서 받은 것 같다고 말했습니다. 하지만 최근에 말한 사람의 말에 따라서도 선물 받는 것이 재미있을 것 같다고 말했으며, 앞으로 언니의 생일이 다가오면서 도시락 케이크를 만들어서 선물로 줄까 생각 중이라고 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 5 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000046은 어렸을 때 꿈이 하루에 한 번씩 바뀌었다고 말했으며, 어렸을 때는 꿈을 선생님께 적어주셔서 학교에서 장래희망을 써오라고 할 때는 항상 엄마가 대신 적어주셨다고 했다. 그리고 어른이 되어서는 회사에 들어가는 것이 현실적인 꿈이라고 말했으며, 비현실적인 꿈은 복권에 당첨돼 돈 많이 버는 백수로서 편하게 살다가 자식들에게 물려주고 기부하는 삶을 꿈꾸고 있다고 했다. 노년에는 귀농을 하거나 시골에서 가족과 함께 편하게 살다가 건강하게 살다가 싶은 꿈을 가지고 있으며, 또 노년에는 카페를 운영하면서 평일에는 카페를 운영하고 주말에는 봉사를 다니며 평화롭게 노년을 보내고 싶다고 했다.\n",
            "\n",
            "SD2000048은 유치원 때는 경찰관, 초등학교 때는 요리사, 중학교 때는 프로게이머, 고등학교 때는 축구 선수나 스포츠 기자 등 다양한 꿈을 가지고 있었다고 말했으며, 어른이 되어서는 사회복지학과를 졸업하고 사회복지 쪽에서 취업을 할지 고민하고 있으며, 또 다른 진로도 고려하고 있다고 했다. 노년에는 귀농을 하거나 시골에서 가족과 함께 편하게 살다가 건강하게 살다가 싶은 꿈을 가지고 있으며, 또 노년에는 카페를 운영하면서 평일에는 카페를 운영하고 주말에는 봉사를 다니며 평화롭게 노년을 보내고 싶다고 했다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000046은 어렸을 적에는 꿈이 하루에 여러 번 바뀌는 경향이 있었고, 어렸을 때의 꿈은 잘 기억이 나지 않는다고 말했습니다. 학교에서 장래 희망을 써야 할 때는 항상 엄마가 대신 적어주셨고, 어른이 되면 회사에 들어가는 것이 현실적인 꿈이라고 말했습니다. 하지만 현실적으로 이루기 어려운 꿈도 있다고 말하며, 미래에 귀농을 하며 소박하게 살고 싶다고 언급했습니다. \n",
            "\n",
            "SD2000048은 유치원 때 경찰관, 초등학교 때 요리사, 중학교 때 프로게이머, 고등학교 때 축구 선수나 스포트스 기자 등 다양한 꿈을 가졌다고 말했습니다. 대학교 때는 꿈이 없다고 말하며, 현실적인 꿈은 사회복지 쪽에서 잘 되고 강연을 하며 많은 사람들 앞에 서고 싶다고 말했습니다. 하지만 사회복지 쪽에 관심이 많지 않아 다른 진로도 고려하고 있다고 말했습니다. 노년에는 귀농을 하거나 카페를 운영하며 봉사를 하며 평화롭게 살고 싶다고 말하며, 늙어서도 카페를 운영하거나 봉사활동을 하며 평화로운 노년을 보내며 싶다고 말했습니다.\n",
            "\n",
            "SD2000048의 말 요약은 다음과 같습니다. \n",
            "\n",
            "SD20020048은 유치원 시절에는 경찰관, 초등 시절에는 요리사, 초등 시설에는 요리사였으며, 중등 시절에는 프로게이머였다고 말했습니다. 고등 시절에는 축구 선수나 스프트스 기자 등 여러 가지 꿈을 가졌으며, 대학교 시절에는 꿈이 없다고 말했다. 현실적인 꿈으로는 사회복지 쪽에서 성공하고 강연을 하여 많은 사람들 앞으로 나서고 싶다고 말했으며, 사회복지 쪽에 큰 관심이 없어서 다른 진로도 고민하고 있다고 말했습니다.\n",
            "\n",
            "SD204008은 노년에는 귀농이나 카페를 운영하여 평화롭게 지내고 싶다고 말했고, 늦은 나이에도 카페를 운영하는 것과 봉사활동을 통해 평화로운 노년에 보내고 싶다고 말한 바 있습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 6 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000048과 SD2000046은 가족의 꿈, 자신의 꿈, 그리고 친구의 꿈에 대해 이야기했습니다. SD2000048은 부모님의 꿈에 대해 이야기하며, 엄마가 아나운서가 되고 싶어 했고, 누나가 작곡가가 꿈이지만 아직 성공하지 못하고 있다고 말했습니다. SD2000048은 아나운서가 되고 싶었지만 현실적으로 이루지 못했기 때문에 가족의 꿈을 본받아 자신의 꿈을 찾아보겠다고 생각했다고 말했습니다. SD2000046은 가족의 꿈에 대해 이야기하며, 엄마가 젊었을 때 작가가 되고 싶었지만 집안 사정이 좋지 않아 포기하고 회사원으로 일하고 있다고 말했습니다. 아빠는 항해사가 꿈이었지만 배를 모는 것이 오래 걸리고 외로워서 다른 꿈을 이루셨다고 말했습니다. SD2000048은 카페를 운영하고 싶어 개인 카페를 운영하고 싶다고 말했습니다. SD2000046은 친구 중에 간호사에서 물리치료사로 꿈을 이룬 친구가 있었고, 군대에서 수의사가 꿈인 친구를 만났으며, 그 친구의 노력과 열정에 영향을 받았다고 말했습니다. 또한, 친구 중에 공장에서 일하고 있는 사람이 사업가가 꿈이지만 부업으로 사업을 시작했지만 잘 안 되고 있다고 말했습니다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000048은 가족의 꿈을 기억하고 있다고 말했습니다. 부모님의 꿈 중에 특히 엄마가 아나ウン서가 되고자 했던 꿈을 기억하고 있습니다. 어렸을 적에 엄마가 아나언서가 되고싶어 발음도 좋았고 책도 많이읽고 유식하다고 말하면서 발음교정연필을 입에물리는 것을 막아달라고 했고, 자기는 아나언서를 꿈꾸고 신문지를 읽어주면서 말하는 법을 가르쳐주었다고 말했습니다. 그리고 저는 엄마의 꿈을 본 후 아나운서를 꿈꾸게 되었지만 현실적으로 이루지 못했으며, 누나가 아나운사가 되고 싶다고 말했지만 만화와 음악에 관심이 많아 만화가가 되고, 사촌 누나가 만화에 관심이 많아서 음악에 관심을 가지게 되었고, 고등학교 때부터 일본 노래를 자주 불렀고, 지금은 작곡가가 되고 있습니다. 부모님의꿈을 본 후 저도 꿈을 생각해봐야겠다고 생각했지만, 부모님은 꿈을 이루지 못했지만 자녀가 꿈을 이루는 것을 기대하고 있습니다.\n",
            "\n",
            "SD2000048이 말한 내용은 다음과 같습니다. \n",
            "\n",
            "SD2000048는 가족의 꿈을 생각해본 적이 있다고 말했습니다. 어렸을때 부모님의 꿈에 관심을 가지면서 아나운서 꿈을 가진 엄마와 아나운서도 되고 싶었던 누나를 생각해본 적은 있지만, 현실적으로 이루어지지 않았습니다. 그리고 부모님의 꿈은 이루어지지 못했지만, 자녀가 꿈에 이루어지길 기대하고 있습니다. \n",
            "\n",
            "SD2008046은 가족의 꿈에 대해 생각해본 적 있다고 말했습니다. 엄마는 젊었을 때 작가가 되겠다고 꿈꿨지만, 집안 사정이 어려워 꿈을 포기하고 회사원으로 일하고 있습니다. 아빠는 항해사가 꿈이었지만, 배를 모는 것이 오래 걸리고 외로워서 다른 꿈을 이루셨지만, 결국 꿈을 이루다고 말했습니다. 그리고 카페 운영에 대해 물어본 후, SD2000048은 프랜차이즈다면 브랜드 규칙에 얽매여서 제식대로 운영하기 어렵다고 말했지만, 개인 카페는 제 식대로 운영하고 싶어 개인 카페를 원한다고 말했습니다.\n",
            "\n",
            "SD2000046은 친구의 꿈에 대해 말했습니다. 친구 중에는 어린 시절부터 간호사, 물리치료사가 꿈인 친구가 있었다고 말했습니다. 처음에는 의사가 꿈이었지만 점차 간호사, 그리고 물리치료사를 꿈꾸게 되었고, 지금은 물리 치료사로 일하고 있습니다. 그리고 친구의 꿈을 이루는 모습을 보고 기분이 좋았고, SD2000046은 자신도 친구의 꿈에 영향을 받았다고 말했습니다. 또 다른 친구는 공장에서 일하면서 부업으로 사업을 꿈꾸고 있지만, 잘 안 되어서 다른 일을 찾고 있다고 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 7 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000049는 최근 헤어진 지 반년이 넘었고, 남자친구를 만나고 싶지만 전남친들한테 데려가서 새로운 남자를 만나는 게 두려워 고민하고 있다. 또한, 교회 오빠가 너무 좋아하지만 모솔이라서 고민이 많다고 말한다. SD2000050는 최근 모솔이었던 남자를 만났다가 연애를 해보고 헤어지고 다시 친구로 돌아가서 잘 지내고 있다고 말한다. 또한, 연상이 좋아하는 편이라서 연상이랑 사귄 적이 많다고 말한다. SD2000049는 연상이 좋아하지만, 그 오빠가 인기가 많아 부담스러워서 티를 내지 못하고 있다. SD2000050는 티를 내서 어필을 해보는 것이 좋다고 말한다. \n",
            "\n",
            " <<post_output>> \n",
            " 화자 SD2000049는 반년 넘게 헤어진 지라 남자친구를 만나고 싶고, 팔짱끼며 돌아다니고 데이트를 많이 하고 싶은데 전남친들이 데려가서 새로운 남자를 만나는 걸 두려워한다고 말했습니다. 또한, 어떤 남자를 만나면 좋을지 모르겠다며, 이름1이 생각해본다면 스타일이 조금 맞는 거 같다며 말했습니다. \n",
            "\n",
            "화자 SD2000050은 최근에 모태 솔로였던 사람과 사귀었다고 말하며, 연애를 처음 해보는 사람들은 연애를 해보면서 느낀다는 것과 모솔인 사람들은 처음 연애를 해서 느낄 수 있는 그런 느낌이 있다고 말했습니다. 또한 화자 SD2000051은 연상이 좋아하는 편이라며, 연상이 연애를 한 사람들은 연애에 대한 느낌이 있다는 것과 연상이 연예인이라면 연예인에 대한 느낌을 말하는 것이라고 말했습니다. \n",
            "\n",
            "SD2000049는 연상이 좋아하지만, 그 오빠는 모솔이고 인기가 많아 부담스러운다고 말하며, 그 오빠가 인기가 많아 친한 언니와도 부담스러움을 느끼고 말투도 딥딥해지고 피하고 있다고 말했습니다. 그리고 그 오빠가 졸업을 앞두고 고향에 가서 살지 고민하고 있다고 말하며, 그게 끝나면 슬퍼서 우울해질 것 같다고 말했습니다. \n",
            "\n",
            "또한, 화자 SD2000041은 엑스와는 한 번도 좋지 않았던 적이 없다고 말하며, 한 번 헤어졌을 때 남보다 못한 관계가 되는 게 당연하다고 말했습니다. 그리고 화자 SD200001은 연애를 해본 사람들은 연애의 느낌을 알게 되고, 모솔인 사람들도 연애를 해보고 느낄 수 있는 느낌이 있다고 말을 했습니다. \n",
            "\n",
            "화자SD200001은 연상이 연애했던 사람들은 연애에서 느낀 느낌이 있다고 하며, 연상은 연예인이라도 연예인에 대해 느낀 느낌을 말한다고 말했습니다.\n",
            "\n",
            "화자SD200002는 연상이 연하보다는 더 좋아하는 편이라 말하며, 연상이 인기가 많아 연예인에 대해서도 느낀다는 것이라고 말했습니다.\n",
            "\n",
            "화자는 SD200003은 연상이 인기를 좋아하는 편이라면 연예인을 좋아하는 것과 마찬가지로 연예인에 대하여 느낀다는 것이라 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 8 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000053:\n",
            "- 학창 시절은 조용하고 무난하게 지냈다. 친구들과 사이도 좋았고 성실하게 공부했다. 활발하게 추억을 만들었으면 좋았을 것 같고, 친구들과 선생님들과도 연락을 잘 한다.\n",
            "- name2 씨는 조용하고 불성실한 학생이었다. 친구를 많이 사귀었지만 지금까지도 연락을 잘 안 한다. 도서관을 좋아하지 않았고, 밖에서 운동장에서 친구들과 놀거나 매점에서 친구들과 이야기 나누는 시간을 좋아했다.\n",
            "- 가장 좋아한 과목은 국어였다. 수학 과학은 싫었다. 영어는 점수가 좋지 못했지만, 대학교에서는 수학을 하지 않아도 되서 마음이 편하다.\n",
            "- name1 씨는 수학 과학을 싫고 국어, 사회 같은 과목을 좋아했다. 영어에는 흥미는 있었지만 잘하지 못했으며, 제2 외국어로 일본어를 배웠다. 초반에는 지루했지만 후반에는 새로운 언어를 배운다는 것에 흥미가 생겼다.\n",
            "\n",
            "SD2000052:\n",
            "- 학창 시절은 조용하고 불성실한 학생이었다. 친구를 많이 사귀었지만 지금까지도 연락을 잘 안 한다. 도서관을 좋아했지만, 친구들이랑 놀거나 운동장에서 친구들과 함께 놀거나 매점에서 친구들과 이야기 나누는 시간을 좋아했다.\n",
            "- 가장 좋아한 과목은 국어였다. 수학 과학은 재능이 없고 흥미도 없었다. 영어는 점수가 좋지 못했지만, 대학교에서는 수학을 하지 않아도 되서 마음이 편하다.\n",
            "- name1 씨는 수학 과학을 싫고 국어, 사회 같은 과목을 좋아했다. 영어에는 흥미는 있었지만 잘하지 못했으며, 제2 외국어로 일본어를 배웠다. 초반에는 지루했지만 후반에는 새로운 언어를 배운다는 것에 흥미가 생겼다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000053 씨는 학창시절에 조용하고 무난하게 학창시절을 보냈다고 말했습니다. 그는 친구들과 사이도 좋고, 성실하게 공부했으며, 친구들과 함께 밖에서 운동장을 이용하거나 매점에서 시간을 보내며 스트레스를 풀었다고 했습니다. 또한, 학교 밖에서 운동을 즐기며 활발하게 추억을 만들고 싶다는 후회도 있지만, 친구들과 잘 지내고 선생님들과도 연락을 주고받는 무난한 학생이었다고 했습니다. 그는 여자 고등학교에서 남자 고등학교와 같은 운동장을 사용했기 때문에 남자 아이들과 함께 운동하는 모습을 볼 수 있어 재미있었다고도 했습니다. \n",
            "\n",
            "SD2000053은 name2 씨가 어떤 학생이었냐고 묻자, name2 씨는 조용하고 존재감이 약한 학생이었으며, 공부를 열심해하지도 않았고 불성실하게 학창시기를 보냈다고 했습니다. 친구를 많이 사귈지는 했지만, 지금까지도 꾸준히 지내는 친구는 없고, 도서관을 좋아하지 않았으며, 주로 운동장을 이용하던 학생이었다고 말했습니다. \n",
            "\n",
            "SD2005053은 name2씨가 가장 좋아했던 과학은 문과라면 국어였고, 수학 과학은 싫어했으며, 영어는 점수가 좋지 않았지만 대학교에 가서도 수학은 안 하고 있기 때문에 스트레스는 덜 받고 있다고 했습니다. 그는 또한 제2 외국어인 일본어를 배운 것이 흥미로웠다고도 말했습니다. \n",
            "\n",
            "name2 씨는 학창 때 애니메이션 부에 가입해 애니메이션을 보고 그림을 그리는 활동을 했던 기억이 나고, 선생님 주도하에 하는 활동이 아니라 학생들이 좋아하는 애니메이션에 대해 그림을 그리는 시간을 가졌다고 말했습니다. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [[Sample 9 ]] \n",
            "\n",
            " <<prev_output>> \n",
            " SD2000052는 일본어 전공을 하고 있으며, 제2 외국어로 일본어를 선택한 이유는 평소에 일본 만화나 애니메이션에 관심이 많았기 때문이라고 설명했습니다. 또한, 다른 학생들이 어려워하는 아랍어나 스페인어를 선택하는 것보다 일본어를 선택하는 것이 수월했다고 말했습니다. SD2000052는 어학연수를 가고 싶은 바람을 가지고 있으며, 학교에서 제공하는 프로그램을 통해 다른 나라에서 문화 체험을 할 수 있으면 좋겠다고 생각하고 있습니다.\n",
            "\n",
            "SD2000053은 일본에서 학교를 다녔으며, 처음에는 일본어 어학교에서 공부하다가 일본어를 더 심화학습하기 위해 일본어를 선택했습니다. SD2000053은 인제에서 일본어를 배울 때 어려운 말도 많았지만, 한국어와 문법이 비슷해 빨리 습득할 수 있었다고 말했습니다. 또한, 인제에서 영어는 비슷한 말과 발음이 많아 재미있게 배웠다고 했습니다. SD2000053은 어학연수를 가서 일본에서 학교 생활을 경험하고, 유학 준비를 하면서 일본어를 배웠으며, 일본에 계신 지인분을 통해서 집을 구하고 일본에 갔습니다. SD2000053은 일본에 대해 특별히 관심이 없었지만, 여행 삼아 가보고 싶은 마음에 갔고, 일본에 잘 맞았던 것 같다고 말했습니다. 또한, 한국에 돌아와서 아이를 키우면서 일본어를 잊어버리기도 했지만, 이제 다시 배우고자 하는 마음이 생겼다고 했습니다. \n",
            "\n",
            " <<post_output>> \n",
            " SD2000053 씨는 대학생으로 일본어를 전공하고 있으며, 제2 외국어로는 일본어를 선택했다고 말했습니다. 일본어를 배우는 이유는 평소에 만화나 애니다 보았기 때문이라고 했습니다. SD2000053 씨가 어학연수를 갔을 때는 일본에서 학교 생활을 경험하고 싶어서 유학 준비를 했다고 말했습니다. 처음에는 히라가나와 가타카나를 몰랐지만, 학원을 다니며 배웠고, 집도 구하고 모든 절차를 밟았다고 했습니다. SD3000053 씨는 일본에 대해 특별히 관심이 없었지만, 여행을 가보고 싶었고, 일본이 깨끗하다고 들었기 때문에 갔다가 잘 맞았다고 말했습니다. \n",
            "\n",
            "SD2000053은 일본어를 배우면서 어렵고 잊어버릴까봐 걱정했지만, 지금 name2 씨가 배우고 있는 입장이라 잘 배우고 써서 잊은 채로 가는 것이 중요하다고 말했습니다. 한국에 돌아와서 육아에 집중하면서 일본어를 잊어버렸지만, 이제 다시 배우고 싶다고 했습니다. \n",
            "\n",
            "SD2005053은 일본어에 대해 흥미를 가졌지만, 아직 많이 배우진 않았다고 말했습니다. 한국어와 일본어 문법이 비슷해 빨리 배울 수 있었고, 인제에서 주변 사람들이 일본어로 이야기하는 것을 듣고 빨리 익혔던 것 같다고 했습니다. 영어도 비슷한 말을 많이 사용하고 발음도 비슷해 재미있게 배우고 말했습니다. 하지만 일본어는 어려운 단어도 많아 체감이 많이 들었다고 말했습니다. \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Inference"
      ],
      "metadata": {
        "id": "zJvKp42maVHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RpCKJC-8as9i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m run.test \\\n",
        "    --output result.json \\\n",
        "    --model_id MLP-KTLim/llama-3-Korean-Bllossom-8B \\\n",
        "    --device cuda:0 \\\n",
        "    --adapter_checkpoint_path ./resource/results/checkpoint-62/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2sRTTd8LKnd",
        "outputId": "18f2cb05-93df-4580-b95b-23e1237fe1ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 4/4 [00:05<00:00,  1.47s/it]\n",
            "tokenizer_config.json: 100% 51.1k/51.1k [00:00<00:00, 4.59MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 51.3MB/s]\n",
            "special_tokens_map.json: 100% 444/444 [00:00<00:00, 3.29MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "  0% 0/408 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100% 408/408 [3:14:28<00:00, 28.60s/it]\n"
          ]
        }
      ]
    }
  ]
}