{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input length test\n",
    "\n",
    "> input length 512 이하의 행이 몇 개나 있는지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"alaggung/bart-r3f\"\n",
    "max_length = 512\n",
    "num_beams = 10\n",
    "length_penalty = 1.2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='../cache')\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, cache_dir='../cache')\n",
    "model.eval()\n",
    "\n",
    "# 'inputs', 'labels', 'preds', 'rouge', 'bleu'\n",
    "df = pd.DataFrame()\n",
    "\n",
    "def make_data(path):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    def make_chat(inp):\n",
    "        for cvt in inp['conversation']:\n",
    "            chats = []\n",
    "            speaker = cvt['speaker']\n",
    "            utterance = cvt['utterance']\n",
    "            chats.append(f\"화자{speaker}: {utterance}\")\n",
    "        \n",
    "        chat = \"[BOS]\" + \"[SEP]\".join(chats)  + \"[EOS]\"\n",
    "        return chat\n",
    "\n",
    "    for example in data:\n",
    "        chat = make_chat(example[\"input\"])\n",
    "        \n",
    "        input = tokenizer(chat, return_tensors=\"pt\")\n",
    "        if input.input_ids.size(1) > 512:\n",
    "            continue\n",
    "\n",
    "        inputs.append(input)\n",
    "        labels.append(example[\"output\"])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "inputs, labels = make_data(\"/mnt/c/Users/hwyew/Downloads/korean_dialogue/korean_dialog/resource/data/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanspell 성능 테스트\n",
    "\n",
    "대화체에서도 맞춤법 교정이 유효한가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/hwyew/Downloads/korean_dialogue/korean_dialog/py-hanspell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwyewon/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/c/Users/hwyew/Downloads/korean_dialogue/korean_dialog/py-hanspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7f09f275f8f4fea55bf2d825b99a2f58ea887506\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "def get_passport_key():\n",
    "    \"\"\"네이버에서 '네이버 맞춤법 검사기' 페이지에서 passportKey를 획득\n",
    "\n",
    "        - 네이버에서 '네이버 맞춤법 검사기'를 띄운 후 \n",
    "        html에서 passportKey를 검색하면 값을 찾을 수 있다.\n",
    "\n",
    "        - 찾은 값을 spell_checker.py 48 line에 적용한다.\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=네이버+맞춤법+검사기\"\n",
    "    res = requests.get(url)\n",
    "\n",
    "    html_text = res.text\n",
    "\n",
    "    match = re.search(r'passportKey=([^&\"}]+)', html_text)\n",
    "    if match:\n",
    "        passport_key = match.group(1)\n",
    "        return passport_key\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def fix_spell_checker_py_code(file_path, passportKey):\n",
    "    print(passportKey)\n",
    "    \"\"\"획득한 passportkey를 spell_checker.py파일에 적용\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = r\"'passportKey': '.*'\"\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as input_file:\n",
    "        content = input_file.read()\n",
    "        modified_content = re.sub(pattern, f\"'passportKey': '{passportKey}'\", content)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(modified_content)\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "# before run\n",
    "spell_checker_file_path = './hanspell/spell_checker.py'\n",
    "\n",
    "passport_key = get_passport_key()\n",
    "if passport_key:\n",
    "    fix_spell_checker_py_code(spell_checker_file_path, passport_key)\n",
    "else:\n",
    "    print(\"passportKey를 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checked(result=True, original='나도 인제 안 미루고 맞아는 보려고. 맞아서 소용없으면 소용없는 거고 또 맞아서 좋을 수도 있는 거니까. 그래서 안 걸리면 더 좋은 거고. 가 한번 name3이가 얘기한 대로 혜택 받을 수 있으면 받아가지고 맞아보고.', checked='나도 인제 안 미루고 맞아는 보려고. 맞아서 소용없으면 소용없는 거고 또 맞아서 좋을 수도 있는 거니까. 그래서 안 걸리면 더 좋은 거고. 가 한번 name3이가 얘기한 대로 혜택받을 수 있으면 받아가지고 맞아보고.', errors=1, words=OrderedDict([('나도', 0), ('인제', 0), ('안', 0), ('미루고', 0), ('맞아는', 0), ('보려고.', 0), ('맞아서', 0), ('소용없으면', 0), ('소용없는', 0), ('거고', 0), ('또', 0), ('좋을', 0), ('수도', 0), ('있는', 0), ('거니까.', 0), ('그래서', 0), ('걸리면', 0), ('더', 0), ('좋은', 0), ('거고.', 0), ('가', 0), ('한번', 0), ('name3이가', 0), ('얘기한', 0), ('대로', 0), ('혜택받을', 2), ('수', 0), ('있으면', 0), ('받아가지고', 0), ('맞아보고.', 0)]), time=0.07621264457702637)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "result = spell_checker.check(u'나도 인제 안 미루고 맞아는 보려고. 맞아서 소용없으면 소용없는 거고 또 맞아서 좋을 수도 있는 거니까. 그래서 안 걸리면 더 좋은 거고. 가 한번 name3이가 얘기한 대로 혜택 받을 수 있으면 받아가지고 맞아보고.')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복 어구 없애기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 테스트 문자열 리스트\n",
    "test_strings = [\n",
    "    \"name1 is John\",\n",
    "    \"name123\",\n",
    "    \"My name1 is Jane\",\n",
    "    \"name_underscore\",\n",
    "    \"123name\",\n",
    "    \"너는 유산균 아직 안 먹였으면 한번 알아봐가지고 특히 name1이 먼저 먹여. name1이가 밥도 잘 안 먹고 하니까 내가 추천해 주는 거 이로울 만한 거는 없는데 한번 알아봐봐. 있을 거야\"\n",
    "]\n",
    "\n",
    "# 정규표현식 패턴r'\\bname\\S*'\n",
    "pattern = r'name[0-9]\\S*'\n",
    "\n",
    "# 정규표현식을 사용하여 어구 찾기\n",
    "matches = [re.findall(pattern, string) for string in test_strings]\n",
    "\n",
    "# 결과 출력\n",
    "for string, match in zip(test_strings, matches):\n",
    "    print(f\"Original string: {string}\")\n",
    "    print(f\"Matches: {match}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanspell 제외 전처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "def make_data(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    text_list = []\n",
    "    def make_chat(inp):\n",
    "        chat = \"\"\n",
    "        for cvt in inp['conversation']:\n",
    "            chat += cvt['utterance']\n",
    "        return chat\n",
    "\n",
    "    for example in data:\n",
    "        text_list.append(make_chat(example['input']))\n",
    "    \n",
    "    text = ' '.join(text_list)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "FONT_PATH = \"/mnt/c/Users/hwyew/Downloads/korean_dialogue/korean_dialog/NanumSquareNeo-cBd.ttf\"\n",
    "\n",
    "def make_cloud(text, title, top_k, max_words=100):\n",
    "    # plt.rc('font', family='NanumGothicCoding')\n",
    "    wordcloud = WordCloud(font_path=FONT_PATH, max_words=max_words, background_color=\"white\").generate(text)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 15))\n",
    "\n",
    "    top_data = dict(list(wordcloud.words_.items())[:top_k])\n",
    "    labels, values = zip(*top_data.items())\n",
    "\n",
    "    # 막대 그래프 그리기\n",
    "    axs[0].bar(labels, values)\n",
    "    axs[0].set_xlabel('Labels')\n",
    "    axs[0].set_ylabel('Values')\n",
    "    axs[0].set_title(f\"max count words on {title} data (top {top_k})\", fontsize=36)\n",
    "\n",
    "\n",
    "    # 두 번째 그래프: 워드클라우드\n",
    "    axs[1].imshow(wordcloud)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title(f\"max count words on {title} data (max words = {max_words})\", fontsize=36)\n",
    "\n",
    "    # 그래프 간격 조정\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "## Preprocess functions ##\n",
    "def remove_empty_utterance(data:json):\n",
    "    \"\"\"\n",
    "    Remove empty utterances from the data\n",
    "    \"\"\"\n",
    "    for example in data:\n",
    "        example['input']['conversation'] = [cvt for cvt in example['input']['conversation'] if cvt['utterance'] != '']\n",
    "    return data\n",
    "\n",
    "\n",
    "def correct_wrong_output(data:json):\n",
    "    \"\"\"\n",
    "    Correct wrong speakers in outputs of train samples 'train-000401', 'train-000402'\n",
    "    \"\"\"\n",
    "    data[400]['output'] = data[400]['output'].replace('SD2100504','SD2110504')\n",
    "    data[401]['output'] = data[401]['output'].replace('SD2110503','SD2100503')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def file_preprocess(data:json):\n",
    "    data = remove_empty_utterance(data)\n",
    "    data = correct_wrong_output(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "불용어 처리\n",
    "- name1, name2..\n",
    "- 뒤에 물결이 붙는 경우 (\"음~\", \"아~\")\n",
    "- 그, 뭐, 어, 인제, 막, 아, 음, 읍, 오, 으\n",
    "- 한 글자가 두번 이상 반복되는 경우 (\"또 또\", \"그 그\")\n",
    "\"\"\"\n",
    "\n",
    "stopwords_pattern = [r'name[0-9]\\S*', r'\\w~', r'\\b으\\b', r'\\b그\\b', r'\\b뭐\\b', r'\\b어\\b',  r'\\b인제\\b', r'\\b막\\b', r'\\b아\\b', r'\\b음\\b', r'\\b읍\\b', r'\\b오\\b', r'\\b으\\b']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    for pattern in stopwords_pattern:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # 두 번 이상 반복되는 경우\n",
    "    text = re.sub(r'\\b(\\w)\\s+\\1\\b', r'\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# stopwords + 반복어구 제거\n",
    "def text_preprocess(text):\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_clean_data(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data = file_preprocess(data)\n",
    "    \n",
    "    text_list = []\n",
    "    def make_chat(inp):\n",
    "        chat = \"\"\n",
    "        for cvt in inp['conversation']:\n",
    "            chat += cvt['utterance']\n",
    "\n",
    "        return text_preprocess(chat)\n",
    "\n",
    "    for example in tqdm(data):\n",
    "        text_list.append(make_chat(example['input']))\n",
    "    \n",
    "    text = ' '.join(text_list)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 그래서 정말 슬펐어'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'name[0-9]\\S*', '', \"name1이가 그래서 정말 슬펐어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-22 04:04\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 현재 날짜와 시간 가져오기\n",
    "now = datetime.now()\n",
    "\n",
    "# 날짜와 시간을 문자열로 포맷팅\n",
    "current_time = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 화자 1 - 화자 2\n",
    "\n",
    "꼭 넣어줘야 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART 요약 테스트\n",
    "\n",
    "요약해서 input length를 줄인다면?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_dialog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
